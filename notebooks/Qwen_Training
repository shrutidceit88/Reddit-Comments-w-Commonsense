{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":94635,"databundleVersionId":13121456,"sourceType":"competition"},{"sourceId":12643252,"sourceType":"datasetVersion","datasetId":7916512},{"sourceId":12823350,"sourceType":"datasetVersion","datasetId":8033597},{"sourceId":12870970,"sourceType":"datasetVersion","datasetId":8141813},{"sourceId":10285957,"sourceType":"datasetVersion","datasetId":6365346}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-28T23:25:05.286353Z","iopub.execute_input":"2025-08-28T23:25:05.286842Z","iopub.status.idle":"2025-08-28T23:25:06.597161Z","shell.execute_reply.started":"2025-08-28T23:25:05.286806Z","shell.execute_reply":"2025-08-28T23:25:06.596188Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/jigsaw-agile-community-rules/sample_submission.csv\n/kaggle/input/jigsaw-agile-community-rules/train.csv\n/kaggle/input/jigsaw-agile-community-rules/test.csv\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/model.safetensors.index.json\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/model-00003-of-00004.safetensors\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/config.json\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/merges.txt\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/model-00001-of-00004.safetensors\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/tokenizer.json\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/vocab.json\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/tokenizer_config.json\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/chat_template.jinja\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/model-00004-of-00004.safetensors\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/special_tokens_map.json\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/model-00002-of-00004.safetensors\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/added_tokens.json\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/Modelfile\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/generation_config.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/finetune.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/__huggingface_repos__.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/requirements.txt\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/README.md\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/runs/Jul31_16-45-02_55092aac9317/events.out.tfevents.1753980309.55092aac9317.383.0\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/runs/Jul31_15-39-22_55092aac9317/events.out.tfevents.1753976368.55092aac9317.105.0\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/adapter_model.safetensors\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/merges.txt\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/trainer_state.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/training_args.bin\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/adapter_config.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/README.md\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/tokenizer.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/vocab.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/tokenizer_config.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/scaler.pt\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/chat_template.jinja\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/scheduler.pt\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/special_tokens_map.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/optimizer.pt\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/rng_state.pth\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/added_tokens.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/adapter_model.safetensors\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/merges.txt\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/trainer_state.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/training_args.bin\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/adapter_config.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/README.md\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/tokenizer.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/vocab.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/tokenizer_config.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/scaler.pt\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/chat_template.jinja\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/scheduler.pt\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/special_tokens_map.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/optimizer.pt\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/rng_state.pth\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/added_tokens.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Chat-LeetCode/adapter_model.safetensors\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Chat-LeetCode/merges.txt\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Chat-LeetCode/adapter_config.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Chat-LeetCode/README.md\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Chat-LeetCode/tokenizer.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Chat-LeetCode/vocab.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Chat-LeetCode/tokenizer_config.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Chat-LeetCode/chat_template.jinja\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Chat-LeetCode/special_tokens_map.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Chat-LeetCode/added_tokens.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Sequence-LeetCode/adapter_model.safetensors\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Sequence-LeetCode/merges.txt\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Sequence-LeetCode/adapter_config.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Sequence-LeetCode/README.md\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Sequence-LeetCode/tokenizer.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Sequence-LeetCode/vocab.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Sequence-LeetCode/tokenizer_config.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Sequence-LeetCode/special_tokens_map.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Sequence-LeetCode/added_tokens.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothCPOTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothXPOTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothAlignPropTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothKTOTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothOnlineDPOTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothPPOTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothGKDTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothRLOOTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothSFTTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothORPOTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothGRPOTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothDPOTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothBCOTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothRewardTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothPRMTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothIterativeSFTTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothDDPOTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothNashMDTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_153856-hw5zv8tr/run-hw5zv8tr.wandb\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_153856-hw5zv8tr/logs/debug.log\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_153856-hw5zv8tr/logs/debug-internal.log\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_153856-hw5zv8tr/files/wandb-summary.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_153856-hw5zv8tr/files/config.yaml\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_153856-hw5zv8tr/files/output.log\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_153856-hw5zv8tr/files/requirements.txt\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_153856-hw5zv8tr/files/wandb-metadata.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_164447-m41n1c6s/run-m41n1c6s.wandb\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_164447-m41n1c6s/logs/debug.log\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_164447-m41n1c6s/logs/debug-internal.log\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_164447-m41n1c6s/files/wandb-summary.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_164447-m41n1c6s/files/config.yaml\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_164447-m41n1c6s/files/output.log\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_164447-m41n1c6s/files/requirements.txt\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_164447-m41n1c6s/files/wandb-metadata.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/huggingface_tokenizers_cache/.locks/models--unsloth--qwen2.5-coder-0.5b-bnb-4bit/31349551d90c7606f325fe0f11bbb8bd5fa0d7c7.lock\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/huggingface_tokenizers_cache/.locks/models--unsloth--qwen2.5-coder-0.5b-bnb-4bit/c8dd4c904ea9bfc3cbaaa50075c13a9a1dab52c9.lock\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/huggingface_tokenizers_cache/.locks/models--unsloth--qwen2.5-coder-0.5b-bnb-4bit/4783fe10ac3adce15ac8f358ef5462739852c569.lock\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/huggingface_tokenizers_cache/.locks/models--unsloth--qwen2.5-coder-0.5b-bnb-4bit/630e242dd9b9ba3ac98f68aecd23f65ec95efa7e.lock\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/huggingface_tokenizers_cache/.locks/models--unsloth--qwen2.5-coder-0.5b-bnb-4bit/c2aa2851ea30d00c2c99a92741925741fb894100.lock\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/huggingface_tokenizers_cache/.locks/models--unsloth--qwen2.5-coder-0.5b-bnb-4bit/2f2f7ed8cf1b5a91f2bbb383cb767e679c0a6aed.lock\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/huggingface_tokenizers_cache/models--unsloth--qwen2.5-coder-0.5b-bnb-4bit/refs/main\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/huggingface_tokenizers_cache/models--unsloth--qwen2.5-coder-0.5b-bnb-4bit/blobs/31349551d90c7606f325fe0f11bbb8bd5fa0d7c7\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/huggingface_tokenizers_cache/models--unsloth--qwen2.5-coder-0.5b-bnb-4bit/blobs/630e242dd9b9ba3ac98f68aecd23f65ec95efa7e\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/huggingface_tokenizers_cache/models--unsloth--qwen2.5-coder-0.5b-bnb-4bit/blobs/c2aa2851ea30d00c2c99a92741925741fb894100\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/huggingface_tokenizers_cache/models--unsloth--qwen2.5-coder-0.5b-bnb-4bit/blobs/2f2f7ed8cf1b5a91f2bbb383cb767e679c0a6aed\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/huggingface_tokenizers_cache/models--unsloth--qwen2.5-coder-0.5b-bnb-4bit/blobs/c8dd4c904ea9bfc3cbaaa50075c13a9a1dab52c9\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/huggingface_tokenizers_cache/models--unsloth--qwen2.5-coder-0.5b-bnb-4bit/blobs/4783fe10ac3adce15ac8f358ef5462739852c569\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/huggingface_tokenizers_cache/models--unsloth--qwen2.5-coder-0.5b-bnb-4bit/.no_exist/6a59d74d1eaf2f3687e7caa03723f01ace6cdafb/chat_template.jinja\n/kaggle/input/qwen2-5-0-5b/config.json\n/kaggle/input/qwen2-5-0-5b/merges.txt\n/kaggle/input/qwen2-5-0-5b/LICENSE\n/kaggle/input/qwen2-5-0-5b/README.md\n/kaggle/input/qwen2-5-0-5b/tokenizer.json\n/kaggle/input/qwen2-5-0-5b/vocab.json\n/kaggle/input/qwen2-5-0-5b/tokenizer_config.json\n/kaggle/input/qwen2-5-0-5b/model.safetensors\n/kaggle/input/qwen2-5-0-5b/.gitattributes\n/kaggle/input/qwen2-5-0-5b/generation_config.json\n/kaggle/input/qwen2-5-0-5b-instruct/__huggingface_repos__.json\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/config.json\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/merges.txt\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/LICENSE\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/README.md\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/tokenizer.json\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/vocab.json\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/tokenizer_config.json\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/model.safetensors\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.gitattributes\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/generation_config.json\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/.gitignore\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/tokenizer_config.json.lock\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/LICENSE.lock\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/merges.txt.metadata\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/tokenizer.json.metadata\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/tokenizer.json.lock\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/tokenizer_config.json.metadata\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/.gitattributes.lock\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/merges.txt.lock\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/config.json.metadata\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/model.safetensors.metadata\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/generation_config.json.metadata\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/vocab.json.lock\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/.gitattributes.metadata\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/model.safetensors.lock\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/generation_config.json.lock\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/vocab.json.metadata\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/config.json.lock\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/LICENSE.metadata\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/README.md.metadata\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/README.md.lock\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ===== Qwen2.5-0.5B cross-encoder, head-only training, 5-fold =====\n!pip -q install \"transformers==4.44.2\" \"accelerate==0.33.0\"\n\nimport os, gc, warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    DataCollatorWithPadding,\n    Trainer,\n    TrainingArguments,\n    set_seed,\n)\n\n# ---------------- Config ----------------\nDATA_DIR  = \"/kaggle/input/jigsaw-agile-community-rules\"\nTRAIN_CSV = f\"{DATA_DIR}/train.csv\"\n\nMODEL_ID  = \"Qwen/Qwen2.5-0.5B\"    # small & stable\nOUT_ROOT  = \"/kaggle/working/qwen25_ce_headonly\"\nos.makedirs(OUT_ROOT, exist_ok=True)\n\nSEED=42; N_FOLDS=5\nMAX_LEN=256\nEPOCHS=2\nTRAIN_BS=4\nGRAD_ACC=4\nLR=2e-4\nWARMUP=0.05\n\nset_seed(SEED)\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# ------------- Build paired inputs -------------\ndef _clip(x):\n    x = \"\" if pd.isna(x) else str(x).strip()\n    return x if 0 < len(x) < 300 else \"\"\n\ndef build_text_a(row):\n    sub  = str(row[\"subreddit\"])\n    rule = str(row[\"rule\"])\n    pos1 = _clip(row.get(\"positive_example_1\",\"\"))\n    neg1 = _clip(row.get(\"negative_example_1\",\"\"))\n    parts = [f\"r/{sub}\", f\"Rule: {rule}\"]\n    if pos1: parts.append(f\"Yes: {pos1}\")\n    if neg1: parts.append(f\"No: {neg1}\")\n    return \" | \".join(parts)\n\ndef prepare_df(df):\n    df = df.copy()\n    df[\"text_a\"] = df.apply(build_text_a, axis=1)\n    df[\"text_b\"] = df[\"body\"].astype(str)\n    return df\n\ndf = pd.read_csv(TRAIN_CSV)\ndf = prepare_df(df)\ny  = df[\"rule_violation\"].astype(int).values\n\n# ------------- Tokenizer (set PAD) -------------\ntok = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True, trust_remote_code=True)\n# Use EOS as PAD if PAD missing\nif tok.pad_token is None:\n    if tok.eos_token is None:\n        tok.add_special_tokens({\"eos_token\":\"</s>\"})\n    tok.pad_token = tok.eos_token\ntok.padding_side = \"right\"  # OK for seq cls\n\ncollator = DataCollatorWithPadding(tokenizer=tok)\n\n# ------------- Dataset -------------\nclass PairDataset(Dataset):\n    def __init__(self, df, labels=None, max_len=256):\n        self.a = df[\"text_a\"].tolist()\n        self.b = df[\"text_b\"].tolist()\n        self.labels = labels\n        self.max_len = max_len\n    def __len__(self): return len(self.a)\n    def __getitem__(self, i):\n        item = tok(self.a[i], self.b[i], truncation=True, max_length=self.max_len)\n        if self.labels is not None:\n            item[\"labels\"] = int(self.labels[i])\n        return item\n\n# ------------- Model builder (freeze base, train head) -------------\ndef build_headonly_model():\n    model = AutoModelForSequenceClassification.from_pretrained(\n        MODEL_ID,\n        num_labels=2,\n        trust_remote_code=True,\n        torch_dtype=torch.float16 if device==\"cuda\" else torch.float32,\n    )\n\n    model.config.use_cache = False\n    \n    # ensure model knows PAD\n    model.config.pad_token_id = tok.pad_token_id\n    model.config.problem_type = \"single_label_classification\"\n    \n    \n    # if we ever added a token above, make sure embeddings match\n    if model.get_input_embeddings().num_embeddings != len(tok):\n        model.resize_token_embeddings(len(tok))\n\n    hidden = model.config.hidden_size\n\n    # fresh head\n    model.score = torch.nn.Linear(hidden, 2).to(device)\n    torch.nn.init.xavier_uniform_(model.score.weight)\n    torch.nn.init.zeros_(model.score.bias)\n    \n    # freeze all but classifier head\n    for n, p in model.named_parameters():\n        if not any(k in n for k in [\"classifier\",\"score\",\"pooler.dense\"]):\n            p.requires_grad = False\n    return model.to(device)\n\n# ------------- CV Train -------------\nskf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\noof = np.zeros(len(df), dtype=float)\n\nfor fold, (trn_idx, val_idx) in enumerate(skf.split(df, y), 1):\n    print(f\"\\n===== Fold {fold}/{N_FOLDS} =====\")\n    dtr = PairDataset(df.iloc[trn_idx], y[trn_idx], MAX_LEN)\n    dvl = PairDataset(df.iloc[val_idx], y[val_idx], MAX_LEN)\n\n    model = build_headonly_model()\n\n    args = TrainingArguments(\n        output_dir=f\"{OUT_ROOT}/fold{fold}\",\n        num_train_epochs=EPOCHS,\n        per_device_train_batch_size=TRAIN_BS,\n        gradient_accumulation_steps=GRAD_ACC,\n        learning_rate=LR,\n        warmup_ratio=WARMUP,\n        weight_decay=0.01,\n        logging_steps=50,\n        save_strategy=\"no\",\n        report_to=\"none\",\n        remove_unused_columns=False,\n        fp16=(device==\"cuda\"),\n        dataloader_pin_memory=False,\n        seed=SEED,\n    )\n\n    trainer = Trainer(\n        model=model,\n        args=args,\n        train_dataset=dtr,\n        tokenizer=tok,\n        data_collator=collator,\n    )\n    trainer.train()\n\n    # Save fold\n    save_dir = f\"{OUT_ROOT}/fold{fold}\"\n    os.makedirs(save_dir, exist_ok=True)\n    trainer.model.save_pretrained(save_dir)\n    tok.save_pretrained(save_dir)\n\n    # OOF AUC\n    model.eval()\n    dl = DataLoader(dvl, batch_size=128, shuffle=False, collate_fn=collator)\n    \n    preds = []\n    with torch.no_grad():\n        for batch in dl:\n            for k in batch:\n                batch[k] = batch[k].to(device)\n                \n            logits_fp32 = model(**batch).logits.float()  # cast to fp32\n            # remove any inf/NaN produced by fp16 math\n            logits_fp32 = torch.nan_to_num(logits_fp32, nan=0.0, posinf=1e4, neginf=-1e4)\n            prob = torch.softmax(logits_fp32, dim=1)[:, 1]\n            prob = torch.nan_to_num(prob, nan=0.5)  # final guard\n            preds.append(prob.detach().cpu().numpy())\n\n    prob1 = np.concatenate(preds)\n    prob1 = np.clip(prob1, 0.0, 1.0)\n\n    # (optional) if a freak fold gives all NaNs for any reason:\n    if np.isnan(prob1).any():\n        prob1 = np.nan_to_num(prob1, nan=0.5)\n\n    oof[val_idx] = prob1\n    print(f\"Fold {fold} AUC: {roc_auc_score(y[val_idx], prob1):.4f}\")\n\n    del trainer, model, dtr, dvl, dl, preds, prob1\n    gc.collect()\n    if torch.cuda.is_available(): torch.cuda.empty_cache()\n\nprint(f\"\\nOOF AUC: {roc_auc_score(y, oof):.4f}\")\npd.DataFrame({\"oof\": oof, \"y\": y}).to_csv(f\"{OUT_ROOT}/oof.csv\", index=False)\nprint(\"Saved folds under:\", OUT_ROOT)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T23:51:16.317826Z","iopub.execute_input":"2025-08-28T23:51:16.318768Z","iopub.status.idle":"2025-08-29T00:04:23.537916Z","shell.execute_reply.started":"2025-08-28T23:51:16.318728Z","shell.execute_reply":"2025-08-29T00:04:23.536947Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"\n===== Fold 1/5 =====\n","output_type":"stream"},{"name":"stderr","text":"Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-0.5B and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [100/100 02:11, Epoch 1/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>25850.565000</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Fold 1 AUC: 0.5000\n\n===== Fold 2/5 =====\n","output_type":"stream"},{"name":"stderr","text":"Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-0.5B and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [100/100 02:11, Epoch 1/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>13440.901300</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Fold 2 AUC: 0.5000\n\n===== Fold 3/5 =====\n","output_type":"stream"},{"name":"stderr","text":"Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-0.5B and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [100/100 02:11, Epoch 1/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>14801.972500</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Fold 3 AUC: 0.5000\n\n===== Fold 4/5 =====\n","output_type":"stream"},{"name":"stderr","text":"Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-0.5B and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [100/100 02:13, Epoch 1/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>22400.637500</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Fold 4 AUC: 0.5000\n\n===== Fold 5/5 =====\n","output_type":"stream"},{"name":"stderr","text":"Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-0.5B and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [100/100 02:12, Epoch 1/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>13211.216200</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Fold 5 AUC: 0.5000\n\nOOF AUC: 0.5000\nSaved folds under: /kaggle/working/qwen25_ce_headonly\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os, gc, warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    DataCollatorWithPadding,\n    Trainer,\n    TrainingArguments,\n    set_seed,\n)\n\n# ---- Paths / settings\nDATA_DIR = \"/kaggle/input/jigsaw-agile-community-rules\"\nTRAIN_CSV = f\"{DATA_DIR}/train.csv\"\nMODEL_ID  = \"/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2\"\nOUT_ROOT  = \"/kaggle/working\"\n\nSEED=42; N_FOLDS=5\nMAX_LEN=384; EPOCHS=2\nBS_TRAIN=8; GRAD_ACC=2; LR=2e-5\n\nset_seed(SEED)\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# ---- Build pair inputs\ndef _clean(x):\n    x = \"\" if pd.isna(x) else str(x).strip()\n    return x if (0 < len(x) < 300) else \"\"\n\ndef build_text_a(row):\n    rule = str(row[\"rule\"])\n    sub  = str(row[\"subreddit\"])\n    pos1 = _clean(row.get(\"positive_example_1\", \"\"))\n    neg1 = _clean(row.get(\"negative_example_1\", \"\"))\n    parts = [f\"r/{sub}\", f\"Rule: {rule}\"]\n    if pos1: parts.append(f\"Yes: {pos1}\")\n    if neg1: parts.append(f\"No: {neg1}\")\n    return \" | \".join(parts)\n\ndef build_pair_df(df):\n    df = df.copy()\n    df[\"text_a\"] = df.apply(build_text_a, axis=1)\n    df[\"text_b\"] = df[\"body\"].astype(str)\n    return df\n\n# ---- Data\ndf = pd.read_csv(TRAIN_CSV)\ndf = build_pair_df(df)\ny = df[\"rule_violation\"].astype(int).values\n\n# ---- Tokenizer\ntok = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\nif tok.pad_token is None:\n    tok.pad_token = tok.eos_token\n\n# ---- Dataset / collator\nclass PairDataset(Dataset):\n    def __init__(self, df, labels=None, max_len=384):\n        self.a = df[\"text_a\"].tolist()\n        self.b = df[\"text_b\"].tolist()\n        self.labels = labels\n        self.max_len = max_len\n    def __len__(self): return len(self.a)\n    def __getitem__(self, i):\n        item = tok(self.a[i], self.b[i], truncation=True, max_length=self.max_len)\n        if self.labels is not None:\n            item[\"labels\"] = int(self.labels[i])\n        return item\n\ncollator = DataCollatorWithPadding(tokenizer=tok, pad_to_multiple_of=8 if device==\"cuda\" else None)\n\n# ---- 5-fold train (no fancy callbacks/eval)\nskf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\noof = np.zeros(len(df), dtype=float)\n\nfor fold, (trn_idx, val_idx) in enumerate(skf.split(df, y), 1):\n    print(f\"\\n===== Fold {fold}/{N_FOLDS} =====\")\n    dtr = PairDataset(df.iloc[trn_idx], y[trn_idx], MAX_LEN)\n    dvl = PairDataset(df.iloc[val_idx], y[val_idx], MAX_LEN)\n\n    model = AutoModelForSequenceClassification.from_pretrained(\n        MODEL_ID, num_labels=2, problem_type=\"single_label_classification\"\n    )\n\n    args = TrainingArguments(\n        output_dir=f\"{OUT_ROOT}/qwen{fold}\",\n        num_train_epochs=EPOCHS,\n        per_device_train_batch_size=BS_TRAIN,\n        gradient_accumulation_steps=GRAD_ACC,\n        learning_rate=LR,\n        warmup_ratio=0.05,\n        weight_decay=0.01,\n        logging_steps=50,\n        save_strategy=\"no\",\n        report_to=\"none\",\n        remove_unused_columns=False,\n        fp16=(device==\"cuda\"),\n        dataloader_pin_memory=False,\n        seed=SEED,\n    )\n\n    trainer = Trainer(\n        model=model,\n        args=args,\n        train_dataset=dtr,\n        tokenizer=tok,\n        data_collator=collator,\n    )\n\n    trainer.train()\n\n    # Save fold\n    trainer.model.save_pretrained(f\"{OUT_ROOT}/qwen{fold}\")\n    tok.save_pretrained(f\"{OUT_ROOT}/qwen{fold}\")\n\n    # OOF\n    pred_logits = []\n    dl = DataLoader(dvl, batch_size=32, shuffle=False, collate_fn=collator)\n    model.eval(); model.to(device)\n    with torch.no_grad():\n        for batch in dl:\n            for k in batch: batch[k] = batch[k].to(device)\n            out = model(**batch).logits\n            pred_logits.append(out.detach().cpu().numpy())\n    logits = np.concatenate(pred_logits)\n    prob1 = torch.softmax(torch.tensor(logits), dim=1).numpy()[:, 1]\n    oof[val_idx] = prob1\n    print(f\"Fold {fold} AUC: {roc_auc_score(y[val_idx], prob1):.4f}\")\n\n    del model, trainer, dtr, dvl, dl, pred_logits, logits\n    gc.collect()\n    if device==\"cuda\": torch.cuda.empty_cache()\n\nprint(f\"\\nOOF AUC: {roc_auc_score(y, oof):.4f}\")\npd.DataFrame({\"oof\": oof, \"y\": y}).to_csv(f\"{OUT_ROOT}/qwen.csv\", index=False)\nprint(\"\\nSaved fold folders under /kaggle/working/qwenfold1..5\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T22:35:35.841897Z","iopub.execute_input":"2025-08-28T22:35:35.842727Z","iopub.status.idle":"2025-08-28T22:37:17.826714Z","shell.execute_reply.started":"2025-08-28T22:35:35.842696Z","shell.execute_reply":"2025-08-28T22:37:17.821459Z"}},"outputs":[{"name":"stdout","text":"\n===== Fold 1/5 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d0595c992d64a2ab05f8e69b0b0151c"}},"metadata":{}},{"name":"stderr","text":"Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2 and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2 and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1854986443.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m     )\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     trainer = Trainer(\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    533\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"quantization_method\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mQuantizationMethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBITS_AND_BYTES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         ):\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_move_model_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;31m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_move_model_to_device\u001b[0;34m(self, model, device)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_move_model_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m         \u001b[0;31m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mParallelMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tie_weights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2903\u001b[0m                     \u001b[0;34m\" `dtype` by passing the correct `torch_dtype` argument.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 )\n\u001b[0;32m-> 2905\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2907\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1341\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m     def register_full_backward_pre_hook(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1327\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     )\n\u001b[0;32m-> 1329\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1330\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 260.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 122.12 MiB is free. Process 6301 has 14.62 GiB memory in use. Of the allocated memory 14.44 GiB is allocated by PyTorch, and 85.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 260.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 122.12 MiB is free. Process 6301 has 14.62 GiB memory in use. Of the allocated memory 14.44 GiB is allocated by PyTorch, and 85.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}