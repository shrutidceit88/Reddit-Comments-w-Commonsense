{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":94635,"databundleVersionId":13121456,"sourceType":"competition"},{"sourceId":10285957,"sourceType":"datasetVersion","datasetId":6365346},{"sourceId":12643252,"sourceType":"datasetVersion","datasetId":7916512},{"sourceId":12823350,"sourceType":"datasetVersion","datasetId":8033597},{"sourceId":12870970,"sourceType":"datasetVersion","datasetId":8141813}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-29T13:10:55.068046Z","iopub.execute_input":"2025-08-29T13:10:55.068271Z","iopub.status.idle":"2025-08-29T13:10:57.160740Z","shell.execute_reply.started":"2025-08-29T13:10:55.068244Z","shell.execute_reply":"2025-08-29T13:10:57.160038Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/qwen2-5-0-5b/config.json\n/kaggle/input/qwen2-5-0-5b/merges.txt\n/kaggle/input/qwen2-5-0-5b/LICENSE\n/kaggle/input/qwen2-5-0-5b/README.md\n/kaggle/input/qwen2-5-0-5b/tokenizer.json\n/kaggle/input/qwen2-5-0-5b/vocab.json\n/kaggle/input/qwen2-5-0-5b/tokenizer_config.json\n/kaggle/input/qwen2-5-0-5b/model.safetensors\n/kaggle/input/qwen2-5-0-5b/.gitattributes\n/kaggle/input/qwen2-5-0-5b/generation_config.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/finetune.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/__huggingface_repos__.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/requirements.txt\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/README.md\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/runs/Jul31_16-45-02_55092aac9317/events.out.tfevents.1753980309.55092aac9317.383.0\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/runs/Jul31_15-39-22_55092aac9317/events.out.tfevents.1753976368.55092aac9317.105.0\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/adapter_model.safetensors\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/merges.txt\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/trainer_state.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/training_args.bin\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/adapter_config.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/README.md\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/tokenizer.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/vocab.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/tokenizer_config.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/scaler.pt\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/chat_template.jinja\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/scheduler.pt\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/special_tokens_map.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/optimizer.pt\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/rng_state.pth\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-500/added_tokens.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/adapter_model.safetensors\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/merges.txt\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/trainer_state.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/training_args.bin\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/adapter_config.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/README.md\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/tokenizer.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/vocab.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/tokenizer_config.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/scaler.pt\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/chat_template.jinja\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/scheduler.pt\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/special_tokens_map.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/optimizer.pt\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/rng_state.pth\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/outputs/checkpoint-993/added_tokens.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Chat-LeetCode/adapter_model.safetensors\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Chat-LeetCode/merges.txt\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Chat-LeetCode/adapter_config.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Chat-LeetCode/README.md\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Chat-LeetCode/tokenizer.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Chat-LeetCode/vocab.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Chat-LeetCode/tokenizer_config.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Chat-LeetCode/chat_template.jinja\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Chat-LeetCode/special_tokens_map.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Chat-LeetCode/added_tokens.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Sequence-LeetCode/adapter_model.safetensors\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Sequence-LeetCode/merges.txt\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Sequence-LeetCode/adapter_config.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Sequence-LeetCode/README.md\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Sequence-LeetCode/tokenizer.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Sequence-LeetCode/vocab.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Sequence-LeetCode/tokenizer_config.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Sequence-LeetCode/special_tokens_map.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/Qwen2.5-Coder-0.5B-Base-Sequence-LeetCode/added_tokens.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothCPOTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothXPOTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothAlignPropTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothKTOTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothOnlineDPOTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothPPOTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothGKDTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothRLOOTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothSFTTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothORPOTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothGRPOTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothDPOTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothBCOTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothRewardTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothPRMTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothIterativeSFTTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothDDPOTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/unsloth_compiled_cache/UnslothNashMDTrainer.py\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_153856-hw5zv8tr/run-hw5zv8tr.wandb\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_153856-hw5zv8tr/logs/debug.log\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_153856-hw5zv8tr/logs/debug-internal.log\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_153856-hw5zv8tr/files/wandb-summary.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_153856-hw5zv8tr/files/config.yaml\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_153856-hw5zv8tr/files/output.log\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_153856-hw5zv8tr/files/requirements.txt\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_153856-hw5zv8tr/files/wandb-metadata.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_164447-m41n1c6s/run-m41n1c6s.wandb\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_164447-m41n1c6s/logs/debug.log\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_164447-m41n1c6s/logs/debug-internal.log\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_164447-m41n1c6s/files/wandb-summary.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_164447-m41n1c6s/files/config.yaml\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_164447-m41n1c6s/files/output.log\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_164447-m41n1c6s/files/requirements.txt\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/wandb/run-20250731_164447-m41n1c6s/files/wandb-metadata.json\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/huggingface_tokenizers_cache/.locks/models--unsloth--qwen2.5-coder-0.5b-bnb-4bit/31349551d90c7606f325fe0f11bbb8bd5fa0d7c7.lock\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/huggingface_tokenizers_cache/.locks/models--unsloth--qwen2.5-coder-0.5b-bnb-4bit/c8dd4c904ea9bfc3cbaaa50075c13a9a1dab52c9.lock\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/huggingface_tokenizers_cache/.locks/models--unsloth--qwen2.5-coder-0.5b-bnb-4bit/4783fe10ac3adce15ac8f358ef5462739852c569.lock\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/huggingface_tokenizers_cache/.locks/models--unsloth--qwen2.5-coder-0.5b-bnb-4bit/630e242dd9b9ba3ac98f68aecd23f65ec95efa7e.lock\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/huggingface_tokenizers_cache/.locks/models--unsloth--qwen2.5-coder-0.5b-bnb-4bit/c2aa2851ea30d00c2c99a92741925741fb894100.lock\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/huggingface_tokenizers_cache/.locks/models--unsloth--qwen2.5-coder-0.5b-bnb-4bit/2f2f7ed8cf1b5a91f2bbb383cb767e679c0a6aed.lock\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/huggingface_tokenizers_cache/models--unsloth--qwen2.5-coder-0.5b-bnb-4bit/refs/main\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/huggingface_tokenizers_cache/models--unsloth--qwen2.5-coder-0.5b-bnb-4bit/blobs/31349551d90c7606f325fe0f11bbb8bd5fa0d7c7\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/huggingface_tokenizers_cache/models--unsloth--qwen2.5-coder-0.5b-bnb-4bit/blobs/630e242dd9b9ba3ac98f68aecd23f65ec95efa7e\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/huggingface_tokenizers_cache/models--unsloth--qwen2.5-coder-0.5b-bnb-4bit/blobs/c2aa2851ea30d00c2c99a92741925741fb894100\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/huggingface_tokenizers_cache/models--unsloth--qwen2.5-coder-0.5b-bnb-4bit/blobs/2f2f7ed8cf1b5a91f2bbb383cb767e679c0a6aed\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/huggingface_tokenizers_cache/models--unsloth--qwen2.5-coder-0.5b-bnb-4bit/blobs/c8dd4c904ea9bfc3cbaaa50075c13a9a1dab52c9\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/huggingface_tokenizers_cache/models--unsloth--qwen2.5-coder-0.5b-bnb-4bit/blobs/4783fe10ac3adce15ac8f358ef5462739852c569\n/kaggle/input/qwen2-5-coder-1-5b-base-sequence-lv2/huggingface_tokenizers_cache/models--unsloth--qwen2.5-coder-0.5b-bnb-4bit/.no_exist/6a59d74d1eaf2f3687e7caa03723f01ace6cdafb/chat_template.jinja\n/kaggle/input/jigsaw-agile-community-rules/sample_submission.csv\n/kaggle/input/jigsaw-agile-community-rules/train.csv\n/kaggle/input/jigsaw-agile-community-rules/test.csv\n/kaggle/input/qwen2-5-0-5b-instruct/__huggingface_repos__.json\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/config.json\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/merges.txt\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/LICENSE\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/README.md\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/tokenizer.json\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/vocab.json\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/tokenizer_config.json\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/model.safetensors\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.gitattributes\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/generation_config.json\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/.gitignore\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/tokenizer_config.json.lock\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/LICENSE.lock\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/merges.txt.metadata\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/tokenizer.json.metadata\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/tokenizer.json.lock\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/tokenizer_config.json.metadata\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/.gitattributes.lock\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/merges.txt.lock\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/config.json.metadata\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/model.safetensors.metadata\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/generation_config.json.metadata\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/vocab.json.lock\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/.gitattributes.metadata\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/model.safetensors.lock\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/generation_config.json.lock\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/vocab.json.metadata\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/config.json.lock\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/LICENSE.metadata\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/README.md.metadata\n/kaggle/input/qwen2-5-0-5b-instruct/Qwen/Qwen2.5-Math-1.5B/.cache/huggingface/download/README.md.lock\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/model.safetensors.index.json\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/model-00003-of-00004.safetensors\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/config.json\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/merges.txt\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/model-00001-of-00004.safetensors\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/tokenizer.json\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/vocab.json\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/tokenizer_config.json\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/chat_template.jinja\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/model-00004-of-00004.safetensors\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/special_tokens_map.json\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/model-00002-of-00004.safetensors\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/added_tokens.json\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/Modelfile\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/generation_config.json\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ===== Qwen2.5-0.5B cross-encoder, head-only training, 5-fold =====\n!pip -q install \"transformers==4.44.2\" \"accelerate==0.33.0\"\n\nimport os, gc, warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    DataCollatorWithPadding,\n    Trainer,\n    TrainingArguments,\n    set_seed,\n)\n\n# ---------------- Config ----------------\nDATA_DIR  = \"/kaggle/input/jigsaw-agile-community-rules\"\nTRAIN_CSV = f\"{DATA_DIR}/train.csv\"\n\nMODEL_ID  = \"Qwen/Qwen2.5-0.5B\"    # small & stable\nOUT_ROOT  = \"/kaggle/working/qwen25_ce_headonly\"\nos.makedirs(OUT_ROOT, exist_ok=True)\n\nSEED=42; N_FOLDS=5\nMAX_LEN=256\nEPOCHS=2\nTRAIN_BS=4\nGRAD_ACC=4\nLR=2e-4\nWARMUP=0.05\n\nset_seed(SEED)\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# ------------- Build paired inputs -------------\ndef _clip(x):\n    x = \"\" if pd.isna(x) else str(x).strip()\n    return x if 0 < len(x) < 300 else \"\"\n\ndef build_text_a(row):\n    sub  = str(row[\"subreddit\"])\n    rule = str(row[\"rule\"])\n    pos1 = _clip(row.get(\"positive_example_1\",\"\"))\n    neg1 = _clip(row.get(\"negative_example_1\",\"\"))\n    parts = [f\"r/{sub}\", f\"Rule: {rule}\"]\n    if pos1: parts.append(f\"Yes: {pos1}\")\n    if neg1: parts.append(f\"No: {neg1}\")\n    return \" | \".join(parts)\n\ndef prepare_df(df):\n    df = df.copy()\n    df[\"text_a\"] = df.apply(build_text_a, axis=1)\n    df[\"text_b\"] = df[\"body\"].astype(str)\n    return df\n\ndf = pd.read_csv(TRAIN_CSV)\ndf = prepare_df(df)\ny  = df[\"rule_violation\"].astype(int).values\n\n# ------------- Tokenizer (set PAD) -------------\ntok = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True, trust_remote_code=True)\n# Use EOS as PAD if PAD missing\nif tok.pad_token is None:\n    if tok.eos_token is None:\n        tok.add_special_tokens({\"eos_token\":\"</s>\"})\n    tok.pad_token = tok.eos_token\ntok.padding_side = \"right\"  # OK for seq cls\n\ncollator = DataCollatorWithPadding(tokenizer=tok)\n\n# ------------- Dataset -------------\nclass PairDataset(Dataset):\n    def __init__(self, df, labels=None, max_len=256):\n        self.a = df[\"text_a\"].tolist()\n        self.b = df[\"text_b\"].tolist()\n        self.labels = labels\n        self.max_len = max_len\n    def __len__(self): return len(self.a)\n    def __getitem__(self, i):\n        item = tok(self.a[i], self.b[i], truncation=True, max_length=self.max_len)\n        if self.labels is not None:\n            item[\"labels\"] = torch.tensor(int(self.labels[i]), dtype=torch.long)  # <-- important\n        return item\n\n# ------------- Model builder (freeze base, train head) -------------\ndef build_headonly_model():\n    model = AutoModelForSequenceClassification.from_pretrained(\n        MODEL_ID,\n        num_labels=2,\n        trust_remote_code=True,\n        torch_dtype=torch.float32,\n    )\n    model.config.use_cache = False\n\n    # ensure PAD token id is set\n    model.config.pad_token_id = tok.pad_token_id\n    model.config.problem_type = \"single_label_classification\"\n\n    # keep embeddings in sync if special tokens were added\n    if model.get_input_embeddings().num_embeddings != len(tok):\n        model.resize_token_embeddings(len(tok))\n\n    # build fresh classifier head in SAME dtype/device as the base model\n    # base_dtype  = next(model.parameters()).dtype\n    # base_device = next(model.parameters()).device\n    hidden = model.config.hidden_size\n\n    model.score = torch.nn.Linear(hidden, 2) # , bias=True, device=base_device, dtype=base_dtype\n    torch.nn.init.xavier_uniform_(model.score.weight)\n    torch.nn.init.zeros_(model.score.bias)\n\n    # freeze everything except the classifier head\n    for n, p in model.named_parameters():\n        p.requires_grad = (\"score\" in n)\n\n    return model.to(device)\n\n\n\n# ------------- CV Train -------------\nskf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\noof = np.zeros(len(df), dtype=float)\n\nfor fold, (trn_idx, val_idx) in enumerate(skf.split(df, y), 1):\n    print(f\"\\n===== Fold {fold}/{N_FOLDS} =====\")\n    dtr = PairDataset(df.iloc[trn_idx], y[trn_idx], MAX_LEN)\n    dvl = PairDataset(df.iloc[val_idx], y[val_idx], MAX_LEN)\n\n    model = build_headonly_model()\n\n    \n    \n    args = TrainingArguments(\n        output_dir=f\"{OUT_ROOT}/fold{fold}\",\n        num_train_epochs=EPOCHS,\n        per_device_train_batch_size=TRAIN_BS,\n        gradient_accumulation_steps=GRAD_ACC,\n        learning_rate=LR,\n        warmup_ratio=WARMUP,\n        weight_decay=0.01,\n        logging_steps=50,\n        save_strategy=\"no\",\n        report_to=\"none\",\n        remove_unused_columns=False,\n        fp16=(device==\"cuda\"),\n        dataloader_pin_memory=False,\n        seed=SEED,\n    )\n\n    trainer = Trainer(\n        model=model,\n        args=args,\n        train_dataset=dtr,\n        tokenizer=tok,\n        data_collator=collator,\n    )\n    trainer.train()\n\n    # 🔹 Save model + tokenizer for this fold\n    trainer.model.save_pretrained(f\"{OUT_ROOT}/fold{fold}\")\n    tok.save_pretrained(f\"{OUT_ROOT}/fold{fold}\")\n    print(f\"Saved fold {fold} to {OUT_ROOT}/fold{fold}\")\n\n    # ---------- OOF AUC ----------\n    model.eval()\n    dl = DataLoader(dvl, batch_size=128, shuffle=False, collate_fn=collator)\n    \n    preds = []\n    with torch.no_grad():\n        for batch in dl:\n            for k in batch:\n                batch[k] = batch[k].to(device)\n            logits_fp32 = model(**batch).logits.float()\n            logits_fp32 = torch.nan_to_num(logits_fp32, nan=0.0, posinf=1e4, neginf=-1e4)\n            prob = torch.softmax(logits_fp32, dim=1)[:, 1]\n            prob = torch.nan_to_num(prob, nan=0.5)\n            preds.append(prob.detach().cpu().numpy())\n\n    prob1 = np.concatenate(preds)\n    prob1 = np.clip(prob1, 0.0, 1.0)\n    if np.isnan(prob1).any():\n        prob1 = np.nan_to_num(prob1, nan=0.5)\n\n    oof[val_idx] = prob1\n    print(f\"Fold {fold} AUC: {roc_auc_score(y[val_idx], prob1):.4f}\")\n\n    del trainer, model, dtr, dvl, dl, preds, prob1\n    gc.collect()\n    if torch.cuda.is_available(): torch.cuda.empty_cache()\n\nprint(f\"\\nOOF AUC: {roc_auc_score(y, oof):.4f}\")\npd.DataFrame({\"oof\": oof, \"y\": y}).to_csv(f\"{OUT_ROOT}/oof.csv\", index=False)\nprint(\"Saved folds under:\", OUT_ROOT)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T01:24:47.037814Z","iopub.execute_input":"2025-08-29T01:24:47.038560Z","iopub.status.idle":"2025-08-29T01:49:05.064896Z","shell.execute_reply.started":"2025-08-29T01:24:47.038535Z","shell.execute_reply":"2025-08-29T01:49:05.063672Z"}},"outputs":[],"execution_count":null}]}