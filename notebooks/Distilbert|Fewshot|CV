{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":94635,"databundleVersionId":13121456,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":813452,"sourceType":"datasetVersion","datasetId":427411}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/shrutidceit/xplained-distilbert-fewshot-cv?scriptVersionId=258392045\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"Check my earlier work which are my attempts before to the following notebook:\n- https://www.kaggle.com/code/shrutidceit/basics-xgboost-few-shot-learning?scriptVersionId=258173247\n- https://www.kaggle.com/code/shrutidceit/basic-cv-logistic-pipeline?scriptVersionId=257970214\n- https://www.kaggle.com/code/shrutidceit/tf-idf-logistic?scriptVersionId=256048235\n- https://www.kaggle.com/code/shrutidceit/tf-idf-logistic?scriptVersionId=256068857\n- https://www.kaggle.com/code/shrutidceit/complete-eda\n- https://www.kaggle.com/code/shrutidceit/tf-idf-logistic\n- https://www.kaggle.com/code/shrutidceit/detailed-eda-w-wordcloud\n\n<li>Feel free to share your Feedback - It's very important for me. \n<li>Please upvote to appreciate the attempt","metadata":{}},{"cell_type":"markdown","source":"### Importing necessary libraries\n","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os, gc, random\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nimport torch\nfrom torch.utils.data import Dataset\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T23:57:28.413746Z","iopub.execute_input":"2025-08-26T23:57:28.414423Z","iopub.status.idle":"2025-08-26T23:57:35.3203Z","shell.execute_reply.started":"2025-08-26T23:57:28.4144Z","shell.execute_reply":"2025-08-26T23:57:35.319652Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Let's import a set of building blocks from ***transformers library*** that will be used together for text classification tasks.\n\n<ul>\n    <li><strong>AutoTokenizer:</strong> It is a universal tokenizer loader from provided model (Deberta-v3 in this case) - Tokenizers turn raw text into input IDs (numbers) + attention masks so models can process them.</li>\n    <li><strong>AutoModelForSequenceClassification:</strong> Loads a pretrained Transformer model with a classification head attached. This head is randomly initialized and learns during training.</li>\n    <li><strong>DataCollatorWithPadding:</strong> Handles dynamic padding of batches during training. Since sentences are different lengths, this ensures all samples in a batch are padded to the same length on the fly</li>\n    <li><strong>Trainer:</strong> Hugging Face’s high-level training loop abstraction and handles: Forward/backward pass, Optimizer & scheduler, Evaluation loop, Saving/loading checkpoints</li>\n    <li><strong>TrainingArguments:</strong> Holds all the training hyperparameters and keepds code clean: learning_rate, num_train_epochs, batch_size, save_strategy, logging_steps</li>\n    <li><strong>set_seed:</strong> Set a random seed for reproducibility</li>\n</ul>","metadata":{}},{"cell_type":"code","source":"from transformers import (\n    AutoTokenizer,                    \n    AutoModelForSequenceClassification,\n    DataCollatorWithPadding,\n    Trainer,\n    TrainingArguments,\n    set_seed,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T23:57:37.512618Z","iopub.execute_input":"2025-08-26T23:57:37.513268Z","iopub.status.idle":"2025-08-26T23:58:01.694341Z","shell.execute_reply.started":"2025-08-26T23:57:37.513239Z","shell.execute_reply":"2025-08-26T23:58:01.693722Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Import Data files and Distilbert Model","metadata":{}},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-26T23:58:01.695453Z","iopub.execute_input":"2025-08-26T23:58:01.695986Z","iopub.status.idle":"2025-08-26T23:58:01.718761Z","shell.execute_reply.started":"2025-08-26T23:58:01.695965Z","shell.execute_reply":"2025-08-26T23:58:01.718069Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Importing *train* and *test* files as pandas df","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/jigsaw-agile-community-rules/train.csv\")\ntest  = pd.read_csv(\"/kaggle/input/jigsaw-agile-community-rules/test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T23:58:01.719697Z","iopub.execute_input":"2025-08-26T23:58:01.719892Z","iopub.status.idle":"2025-08-26T23:58:01.992385Z","shell.execute_reply.started":"2025-08-26T23:58:01.719876Z","shell.execute_reply":"2025-08-26T23:58:01.991824Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Defining Model Name","metadata":{}},{"cell_type":"code","source":"MODEL_NAME = \"/kaggle/input/distilbertbaseuncased\" ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T23:58:01.994045Z","iopub.execute_input":"2025-08-26T23:58:01.994457Z","iopub.status.idle":"2025-08-26T23:58:01.997598Z","shell.execute_reply.started":"2025-08-26T23:58:01.994437Z","shell.execute_reply":"2025-08-26T23:58:01.996861Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Defining *training configuration hyperparameters*\n\n<ul>\n    <li><strong>SEED:</strong>Fixed random seed for reproducibility.</li>\n    <li><strong>N_FOLDS:</strong>Number of cross-validation folds.</li>\n    <li><strong>MAX_LEN:</strong>Maximum sequence length for tokenized inputs; Text longer than 384 tokens is truncated, shorter ones are padded.</li>\n    <li><strong>BATCH_TRAIN:</strong>Training batch size</li>\n    <li><strong>BATCH_EVAL:</strong>Batch size during evaluation</li>\n    <li><strong>EPOCHS:</strong>Number of passes through the whole dataset.</li>\n    <li><strong>LR:</strong>Learning rate</li>\n    <li><strong>WEIGHT_DECAY:</strong>L2 regularization(shrinks large weights) - Helps prevent overfitting.</li>\n    <li><strong>WARMUP_RATIO:</strong>Gradually increases LR for the first 10% of steps</li>\n    <li><strong>GRAD_ACC_STEPS:</strong>Gradient accumulation steps - If >1, simulates larger batch sizes by accumulating gradients over several steps before updating weights.</li>\n    <li><strong>FP16:</strong>If GPU is available, use mixed precision (FP16) training.</li>\n</ul>","metadata":{}},{"cell_type":"code","source":"SEED      = 42\nN_FOLDS   = 5\nMAX_LEN   = 512        \nBATCH_TRAIN = 8       \nBATCH_EVAL  = 16\nEPOCHS      = 3        \nLR          = 2e-5\nWEIGHT_DECAY = 0.01\nWARMUP_RATIO = 0.1\nGRAD_ACC_STEPS = 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T23:58:01.998251Z","iopub.execute_input":"2025-08-26T23:58:01.998465Z","iopub.status.idle":"2025-08-26T23:58:02.008844Z","shell.execute_reply.started":"2025-08-26T23:58:01.998444Z","shell.execute_reply":"2025-08-26T23:58:02.008249Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"FP16 = torch.cuda.is_available()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T23:58:02.009675Z","iopub.execute_input":"2025-08-26T23:58:02.009941Z","iopub.status.idle":"2025-08-26T23:58:02.018761Z","shell.execute_reply.started":"2025-08-26T23:58:02.009919Z","shell.execute_reply":"2025-08-26T23:58:02.017942Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"set_seed(SEED) # Sets all the relevant random seeds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T23:58:02.019393Z","iopub.execute_input":"2025-08-26T23:58:02.019586Z","iopub.status.idle":"2025-08-26T23:58:02.033751Z","shell.execute_reply.started":"2025-08-26T23:58:02.019571Z","shell.execute_reply":"2025-08-26T23:58:02.033177Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ***shorten()*** takes a string txt and trims it to atmost max_chars characters\n\n<ul>\n    <li>If the input is NaN/missing value, return an empty string.</li>\n    <li>Converts txt to string (in case it’s not) + .strip() removes leading and trailing spaces. + .replace(\"\\n\", \" \") replaces line breaks with spaces.</li>\n    <li>If the text is longer than max_chars → cut it to the first max_chars characters and append an ellipsis \"…\" ; Otherwise, return the text as is</li>\n</ul>\n\n***ellipsis:*** Adding \"…\" signals: “This text was cut, there’s more not shown.”","metadata":{}},{"cell_type":"code","source":"def _shorten(txt, max_chars=180):\n    if pd.isna(txt): \n        return \"\"\n    txt = str(txt).strip().replace(\"\\n\", \" \")\n    return (txt[:max_chars] + \"…\") if len(txt) > max_chars else txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T23:58:02.034414Z","iopub.execute_input":"2025-08-26T23:58:02.034622Z","iopub.status.idle":"2025-08-26T23:58:02.038837Z","shell.execute_reply.started":"2025-08-26T23:58:02.0346Z","shell.execute_reply":"2025-08-26T23:58:02.038176Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### ***build_text_a()*** takes one row from train/test dataframe and constructs and returns a formatted prompt-like string","metadata":{}},{"cell_type":"code","source":"def build_text_a(row, max_chars_each=160):\n    subreddit = _shorten(row.get(\"subreddit\", \"\"), max_chars_each)      \n    rules  = _shorten(row.get(\"rule\", \"\"), max_chars_each)\n    p1 = _shorten(row.get(\"positive_example_1\", \"\"), max_chars_each)\n    p2 = _shorten(row.get(\"positive_example_2\", \"\"), max_chars_each)\n    n1 = _shorten(row.get(\"negative_example_1\", \"\"), max_chars_each)\n    n2 = _shorten(row.get(\"negative_example_2\", \"\"), max_chars_each)\n    \n    text_a = f\"subreddit: {subreddit}\\nRule: {rules}\\nYes: {p1} | {p2}\\nNo: {n1} | {n2}\"\n    return text_a.strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T23:58:02.039758Z","iopub.execute_input":"2025-08-26T23:58:02.039979Z","iopub.status.idle":"2025-08-26T23:58:02.05Z","shell.execute_reply.started":"2025-08-26T23:58:02.03996Z","shell.execute_reply":"2025-08-26T23:58:02.049499Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Applying ***build_text_a()*** to every row in train/test DataFrames and store the returned string in a new column ***text_a***","metadata":{}},{"cell_type":"code","source":"train[\"text_a\"] = train.apply(build_text_a, axis=1)\ntest[\"text_a\"]  = test.apply(build_text_a, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T23:58:02.052324Z","iopub.execute_input":"2025-08-26T23:58:02.05257Z","iopub.status.idle":"2025-08-26T23:58:02.105609Z","shell.execute_reply.started":"2025-08-26T23:58:02.052555Z","shell.execute_reply":"2025-08-26T23:58:02.105105Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Create clean comment column (text_b) \n<li>It will be paired ---- text_a, text_b ----  for distilbert based classifier.","metadata":{}},{"cell_type":"code","source":"train[\"text_b\"] = train[\"body\"].fillna(\"\").astype(str)\ntest[\"text_b\"]  = test[\"body\"].fillna(\"\").astype(str)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T23:58:02.106138Z","iopub.execute_input":"2025-08-26T23:58:02.10636Z","iopub.status.idle":"2025-08-26T23:58:02.111561Z","shell.execute_reply.started":"2025-08-26T23:58:02.106346Z","shell.execute_reply":"2025-08-26T23:58:02.11088Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Setting Labels to ***int***","metadata":{}},{"cell_type":"code","source":"train[\"label\"] = train[\"rule_violation\"].astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T23:58:02.112309Z","iopub.execute_input":"2025-08-26T23:58:02.112572Z","iopub.status.idle":"2025-08-26T23:58:02.122127Z","shell.execute_reply.started":"2025-08-26T23:58:02.112557Z","shell.execute_reply":"2025-08-26T23:58:02.121622Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Load the right tokenizer for distilbert","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T23:58:02.12294Z","iopub.execute_input":"2025-08-26T23:58:02.123099Z","iopub.status.idle":"2025-08-26T23:58:04.45181Z","shell.execute_reply.started":"2025-08-26T23:58:02.123086Z","shell.execute_reply":"2025-08-26T23:58:04.450989Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Creating class PairDataset \n\n<li>Creates a custom PyTorch Dataset.\n<li>This lets PyTorch’s DataLoader efficiently fetch, batch, and shuffle your training samples\n<li>Converts DataFrame rows into tokenized inputs the model understands.\n<li>Handles paired inputs (rule+examples vs. comment).","metadata":{}},{"cell_type":"code","source":"class PairDataset(Dataset):\n    def __init__(self, df, tokenizer, max_len, with_labels=True):\n        self.df = df.reset_index(drop=True)  # input DataFrame with text_a, text_b, and maybe label.\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        self.with_labels = with_labels # True for training/validation and False for test (since test has no labels)\n\n    def __len__(self): # Tells PyTorch how many samples exist.\n        return len(self.df)\n\n    def __getitem__(self, idx): # Fetches one row of the DataFrame by index.\n        row = self.df.iloc[idx]\n        enc = self.tokenizer(\n            row[\"text_a\"] + \"\\n\" + row[\"text_b\"],\n            max_length=self.max_len,\n            truncation=True,               # truncates across both A and B (longest_first) - ensures neither A nor B overflows the max length.\n            padding=False,                 # let collator pad dynamically\n            return_tensors=\"pt\",\n        )\n        item = {k: v.squeeze(0) for k, v in enc.items()}\n        \n        if self.with_labels:\n            item[\"labels\"] = torch.tensor(row[\"label\"], dtype=torch.long)\n        return item","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T23:58:04.452994Z","iopub.execute_input":"2025-08-26T23:58:04.453293Z","iopub.status.idle":"2025-08-26T23:58:04.459126Z","shell.execute_reply.started":"2025-08-26T23:58:04.453264Z","shell.execute_reply":"2025-08-26T23:58:04.45846Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### DataCollatorWithPadding\n\n<li>When batching samples for training, dynamically pad sequences in the batch using the tokenizer’s pad token, and return attention masks accordingly.\n<li>Every sequence gets padded to max_len (e.g. 512)","metadata":{}},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T23:58:04.460954Z","iopub.execute_input":"2025-08-26T23:58:04.461225Z","iopub.status.idle":"2025-08-26T23:58:04.586018Z","shell.execute_reply.started":"2025-08-26T23:58:04.461204Z","shell.execute_reply":"2025-08-26T23:58:04.585355Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Sigmoid()","metadata":{}},{"cell_type":"code","source":"def sigmoid(x):\n    return 1 / (1 + np.exp(-x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T23:58:06.575334Z","iopub.execute_input":"2025-08-26T23:58:06.575569Z","iopub.status.idle":"2025-08-26T23:58:06.579434Z","shell.execute_reply.started":"2025-08-26T23:58:06.575553Z","shell.execute_reply":"2025-08-26T23:58:06.578577Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Cross-validation setup\n<li> Stratified fold ensures each fold has the same proportion of classes as the original dataset\n<li> Out-Of-Fold(OOF): This initializes a numpy array with zeros, length equal to your training set.\n<li> oof_preds → stores out-of-fold predictions to calculate a robust validation score.\n","metadata":{}},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\noof_preds = np.zeros(len(train), dtype=float)\n\ntest_preds_folds = []\nfold_auc = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T23:58:08.670438Z","iopub.execute_input":"2025-08-26T23:58:08.6707Z","iopub.status.idle":"2025-08-26T23:58:08.674554Z","shell.execute_reply.started":"2025-08-26T23:58:08.670679Z","shell.execute_reply":"2025-08-26T23:58:08.673943Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for fold, (trn_idx, val_idx) in enumerate(skf.split(train, train[\"label\"]), start=1):\n    print(f\"\\n===== Fold {fold}/{N_FOLDS} =====\")\n\n    df_trn = train.iloc[trn_idx].copy()\n    df_val = train.iloc[val_idx].copy()\n\n    ds_trn = PairDataset(df_trn, tokenizer, MAX_LEN, with_labels=True)\n    ds_val = PairDataset(df_val, tokenizer, MAX_LEN, with_labels=True)\n    ds_tst = PairDataset(test, tokenizer, MAX_LEN, with_labels=False)\n\n    model = AutoModelForSequenceClassification.from_pretrained(\n        MODEL_NAME,\n        num_labels=2,   # binary classification\n    )\n\n    args = TrainingArguments(\n    num_train_epochs=EPOCHS,\n    learning_rate=LR,\n    weight_decay=WEIGHT_DECAY,\n    warmup_ratio=WARMUP_RATIO,\n    per_device_train_batch_size=BATCH_TRAIN,\n    per_device_eval_batch_size=BATCH_EVAL,\n    gradient_accumulation_steps=GRAD_ACC_STEPS,\n    logging_steps=100,\n    save_strategy=\"no\",\n    report_to=\"none\",\n    fp16=FP16,\n    dataloader_num_workers=2,\n    seed=SEED + fold,\n)\n     \n    FP16 = torch.cuda.is_available()\n\n    trainer = Trainer(\n        model=model,\n        args=args,\n        train_dataset=ds_trn,\n        eval_dataset=None,\n        tokenizer=tokenizer,\n        data_collator=data_collator,\n    )\n\n    # Train\n    trainer.train()\n\n    # Predict on validation\n    val_out = trainer.predict(ds_val)\n    \n    # val_out.predictions shape: (N, 2) logits\n    val_logits = val_out.predictions\n    val_probs = sigmoid(val_logits[:, 1] - val_logits[:, 0])  \n\n    # Store OOF\n    oof_preds[val_idx] = val_probs\n    val_auc = roc_auc_score(df_val[\"label\"].values, val_probs)\n    fold_auc.append(val_auc)\n    print(f\"Fold {fold} AUC: {val_auc:.5f}\")\n\n    # Predict on test for this fold\n    tst_out = trainer.predict(ds_tst)\n    tst_logits = tst_out.predictions\n    tst_probs  = sigmoid(tst_logits[:, 1] - tst_logits[:, 0])\n    test_preds_folds.append(tst_probs)\n\n    # Memory cleanup\n    del model, trainer, ds_trn, ds_val, ds_tst, val_out, tst_out\n    gc.collect()\n    torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T23:58:09.335799Z","iopub.execute_input":"2025-08-26T23:58:09.336325Z","iopub.status.idle":"2025-08-27T00:20:29.415053Z","shell.execute_reply.started":"2025-08-26T23:58:09.3363Z","shell.execute_reply":"2025-08-27T00:20:29.414333Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"OOF AUC:\", roc_auc_score(train[\"label\"].values, oof_preds))\nprint(\"Fold AUCs:\", [f\"{x:.5f}\" for x in fold_auc])\nprint(\"Mean AUC:\", np.mean(fold_auc))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T00:20:29.416816Z","iopub.execute_input":"2025-08-27T00:20:29.417049Z","iopub.status.idle":"2025-08-27T00:20:29.425041Z","shell.execute_reply.started":"2025-08-27T00:20:29.41703Z","shell.execute_reply":"2025-08-27T00:20:29.424303Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_pred = np.mean(np.column_stack(test_preds_folds), axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T00:20:29.42568Z","iopub.execute_input":"2025-08-27T00:20:29.425869Z","iopub.status.idle":"2025-08-27T00:20:29.43756Z","shell.execute_reply.started":"2025-08-27T00:20:29.425854Z","shell.execute_reply":"2025-08-27T00:20:29.436822Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Final submission","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame({\n    \"row_id\": test[\"row_id\"],\n    \"rule_violation\": np.round(test_pred.astype(float), 2)\n})\n\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T00:20:29.439009Z","iopub.execute_input":"2025-08-27T00:20:29.43924Z","iopub.status.idle":"2025-08-27T00:20:29.469279Z","shell.execute_reply.started":"2025-08-27T00:20:29.43922Z","shell.execute_reply":"2025-08-27T00:20:29.46865Z"}},"outputs":[],"execution_count":null}]}