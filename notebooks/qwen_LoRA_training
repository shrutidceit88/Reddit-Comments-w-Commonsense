{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":94635,"databundleVersionId":13121456,"sourceType":"competition"},{"sourceId":258601733,"sourceType":"kernelVersion"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ===== Simple 5-fold inference (offline) =====\n# Internet OFF. Loads saved fold folders and averages predictions.\nimport os, gc, warnings, numpy as np, pandas as pd, torch\nwarnings.filterwarnings(\"ignore\")\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding\n\n# -------------------------\n# Paths\n# -------------------------\nDATA_DIR   = \"/kaggle/input/jigsaw-agile-community-rules\"\nTEST_CSV   = f\"{DATA_DIR}/test.csv\"\nFOLDS_ROOT = \"/kaggle/input/basic-qwen2-7b\"   # <-- change to your dataset name\nMAX_LEN    = 384\nBS_INFER   = 32\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# -------------------------\n# Utils\n# -------------------------\ndef _clean(x):\n    x = \"\" if pd.isna(x) else str(x).strip()\n    return x if (0 < len(x) < 300) else \"\"\n\ndef build_text_a(row):\n    rule = str(row[\"rule\"])\n    sub  = str(row[\"subreddit\"])\n    pos1 = _clean(row.get(\"positive_example_1\", \"\"))\n    neg1 = _clean(row.get(\"negative_example_1\", \"\"))\n    parts = [f\"r/{sub}\", f\"Rule: {rule}\"]\n    if pos1: parts.append(f\"Yes: {pos1}\")\n    if neg1: parts.append(f\"No: {neg1}\")\n    return \" | \".join(parts)\n\ndef build_pair_df(df):\n    df = df.copy()\n    df[\"text_a\"] = df.apply(build_text_a, axis=1)\n    df[\"text_b\"] = df[\"body\"].astype(str)\n    return df\n\nclass PairTestDS(Dataset):\n    def __init__(self, df, tok, max_len=384):\n        self.a = df[\"text_a\"].tolist()\n        self.b = df[\"text_b\"].tolist()\n        self.tok = tok\n        self.max_len = max_len\n    def __len__(self): return len(self.a)\n    def __getitem__(self, i):\n        return self.tok(self.a[i], self.b[i], truncation=True, max_length=self.max_len)\n\n# -------------------------\n# Load test\n# -------------------------\ntest = pd.read_csv(TEST_CSV)\ntest = build_pair_df(test)\n\n# Find fold folders\nfold_dirs = sorted([os.path.join(FOLDS_ROOT, d)\n                    for d in os.listdir(FOLDS_ROOT)\n                    if d.startswith(\"deberta_ce_fold\") and os.path.isdir(os.path.join(FOLDS_ROOT, d))])\n\nassert len(fold_dirs) >= 1, \"No trained fold folders found. Please add your trained dataset to the notebook.\"\n\n# Use tokenizer from the first fold\ntok = AutoTokenizer.from_pretrained(fold_dirs[0], local_files_only=True, use_fast=True)\nif tok.pad_token is None:\n    tok.pad_token = tok.eos_token\n\ncollator = DataCollatorWithPadding(tokenizer=tok, pad_to_multiple_of=8 if device==\"cuda\" else None)\nds_test  = PairTestDS(test, tok, MAX_LEN)\ndl_test  = DataLoader(ds_test, batch_size=BS_INFER, shuffle=False, collate_fn=collator)\n\n# -------------------------\n# Ensemble folds\n# -------------------------\nall_probs = []\n\nfor fdir in fold_dirs:\n    print(\"Loading:\", fdir)\n    model = AutoModelForSequenceClassification.from_pretrained(fdir, local_files_only=True).to(device)\n    model.eval()\n\n    probs = []\n    with torch.no_grad():\n        for batch in dl_test:\n            for k in list(batch.keys()):\n                batch[k] = batch[k].to(device)\n            out = model(**batch).logits\n            p = torch.softmax(out, dim=1)[:, 1]\n            probs.append(p.detach().cpu().numpy())\n    probs = np.concatenate(probs)\n    all_probs.append(probs.astype(np.float32))\n\n    del model\n    gc.collect()\n    if device==\"cuda\": torch.cuda.empty_cache()\n\npred = np.mean(np.stack(all_probs, axis=0), axis=0)\n\n# -------------------------\n# Save submission\n# -------------------------\nsubmission = pd.DataFrame({\n    \"row_id\": test[\"row_id\"],\n    \"rule_violation\": pred.clip(0, 1)\n})\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}