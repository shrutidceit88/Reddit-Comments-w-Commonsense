{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":94635,"databundleVersionId":13121456,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":12870970,"sourceType":"datasetVersion","datasetId":8141813},{"sourceId":12881821,"sourceType":"datasetVersion","datasetId":8149843}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-28T01:13:03.254793Z","iopub.execute_input":"2025-08-28T01:13:03.254988Z","iopub.status.idle":"2025-08-28T01:13:05.817748Z","shell.execute_reply.started":"2025-08-28T01:13:03.254952Z","shell.execute_reply":"2025-08-28T01:13:05.817030Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/model.safetensors.index.json\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/model-00003-of-00004.safetensors\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/config.json\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/merges.txt\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/model-00001-of-00004.safetensors\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/tokenizer.json\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/vocab.json\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/tokenizer_config.json\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/chat_template.jinja\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/model-00004-of-00004.safetensors\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/special_tokens_map.json\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/model-00002-of-00004.safetensors\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/added_tokens.json\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/Modelfile\n/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2/generation_config.json\n/kaggle/input/qwen2-model-for-jigsaw/qwen2-model/config.json\n/kaggle/input/qwen2-model-for-jigsaw/qwen2-model/merges.txt\n/kaggle/input/qwen2-model-for-jigsaw/qwen2-model/tokenizer.json\n/kaggle/input/qwen2-model-for-jigsaw/qwen2-model/vocab.json\n/kaggle/input/qwen2-model-for-jigsaw/qwen2-model/tokenizer_config.json\n/kaggle/input/qwen2-model-for-jigsaw/qwen2-model/chat_template.jinja\n/kaggle/input/qwen2-model-for-jigsaw/qwen2-model/model.safetensors\n/kaggle/input/qwen2-model-for-jigsaw/qwen2-model/special_tokens_map.json\n/kaggle/input/qwen2-model-for-jigsaw/qwen2-model/added_tokens.json\n/kaggle/input/jigsaw-agile-community-rules/sample_submission.csv\n/kaggle/input/jigsaw-agile-community-rules/train.csv\n/kaggle/input/jigsaw-agile-community-rules/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"MODEL_PATH = \"/kaggle/input/qwen2-7b-instruct-merged-v2/qwen2-7b-instruct-merged_v2\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T01:13:05.818660Z","iopub.execute_input":"2025-08-28T01:13:05.819261Z","iopub.status.idle":"2025-08-28T01:13:05.822794Z","shell.execute_reply.started":"2025-08-28T01:13:05.819241Z","shell.execute_reply":"2025-08-28T01:13:05.822075Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# ===== Qwen2.5 zero/few-shot (no quantization, Kaggle local) =====\nimport os, gc, warnings\nimport pandas as pd\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nwarnings.filterwarnings(\"ignore\")\n\n# ---- Paths: match your sidebar (screenshot)\nDATA_DIR  = \"/kaggle/input/jigsaw-agile-community-rules\"\nMODEL_DIR = MODEL_PATH\nOUT_CSV   = \"submission.csv\"\nOFFLOAD_DIR = \"/kaggle/working/offload\"\nos.makedirs(OFFLOAD_DIR, exist_ok=True)\n\nassert os.path.isdir(DATA_DIR),  f\"Missing data dir: {DATA_DIR}\"\nassert os.path.isdir(MODEL_DIR), f\"Missing model dir: {MODEL_DIR}\"\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# ---- Tokenizer (local only)\ntok = AutoTokenizer.from_pretrained(\n    MODEL_DIR, use_fast=True, trust_remote_code=True, local_files_only=True\n)\ntok.padding_side = \"left\"\nif tok.pad_token is None:\n    tok.pad_token = tok.eos_token\n\n# ---- Model (no bitsandbytes). Auto offload if needed.\n# If you hit OOM, Accelerate will place some blocks on CPU and use OFFLOAD_DIR.\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_DIR,\n    trust_remote_code=True,\n    local_files_only=True,\n    torch_dtype=torch.float16 if DEVICE == \"cuda\" else torch.float32,\n    device_map=\"auto\" if DEVICE == \"cuda\" else None,\n    offload_folder=OFFLOAD_DIR,          # required when device_map puts layers on \"disk\"\n    low_cpu_mem_usage=True,\n)\nmodel.eval()\n\n# ---- Data\ntest_path  = os.path.join(DATA_DIR, \"test.csv\")\nsample_sub = os.path.join(DATA_DIR, \"sample_submission.csv\")\ndf_test = pd.read_csv(test_path)\ndf_sub  = pd.read_csv(sample_sub)\n\n# ---- Prompt building\nSYS_PROMPT = (\n    \"You are given a Reddit comment and a subreddit moderation rule. \"\n    \"Answer strictly with 'Yes' if the comment violates the rule, otherwise 'No'.\"\n)\n\ndef clean(x):\n    x = (x or \"\").strip()\n    return x if x and len(x) < 300 else \"\"\n\ndef build_rule_context(row):\n    pos1, pos2 = clean(row.get(\"positive_example_1\")), clean(row.get(\"positive_example_2\"))\n    neg1, neg2 = clean(row.get(\"negative_example_1\")), clean(row.get(\"negative_example_2\"))\n    shots = []\n    if pos1: shots.append(f\"Example (Violation=Yes): {pos1}\")\n    if neg1: shots.append(f\"Example (Violation=No): {neg1}\")\n    ctx = f\"Subreddit: r/{row['subreddit']}\\nRule: {row['rule']}\\n\"\n    if shots: ctx += \"\\n\".join(shots) + \"\\n\"\n    return ctx\n\ndef build_prompt(row):\n    user = (\n        f\"{SYS_PROMPT}\\n\\n\"\n        + build_rule_context(row)\n        + \"Comment:\\n\"\n        + str(row[\"body\"])\n        + \"\\n\\nAnswer:\"\n    )\n    messages = [{\"role\": \"system\", \"content\": SYS_PROMPT},\n                {\"role\": \"user\",   \"content\": user}]\n    # Use chat template if available; otherwise fallback to plain text\n    try:\n        return tok.apply_chat_template(messages, add_generation_prompt=False, tokenize=False)\n    except Exception:\n        return user\n\n# ---- Map next-token logits to probability of \"Yes\"\nyes_ids = tok.encode(\" Yes\", add_special_tokens=False)\nno_ids  = tok.encode(\" No\",  add_special_tokens=False)\nYES_FIRST = yes_ids[0] if yes_ids else tok.encode(\"Yes\", add_special_tokens=False)[0]\nNO_FIRST  = no_ids[0]  if no_ids  else tok.encode(\"No\",  add_special_tokens=False)[0]\n\n@torch.no_grad()\ndef prob_yes(prompt, max_len=2048):\n    enc = tok(prompt, return_tensors=\"pt\", truncation=True, max_length=max_len)\n    enc = {k: v.to(model.device) for k, v in enc.items()}\n    out = model(**enc)\n    last_logits = out.logits[:, -1, :]\n    sel = torch.stack([last_logits[0, YES_FIRST], last_logits[0, NO_FIRST]])\n    probs = torch.softmax(sel, dim=0)\n    return float(probs[0].item())\n\n# ---- Inference (simple loop)\nprobs = []\nfor i, row in df_test.iterrows():\n    p = build_prompt(row)\n    probs.append(prob_yes(p))\n    if (i + 1) % 200 == 0:\n        print(f\"Inferred {i+1}/{len(df_test)}\")\n\n\n# Clean up\ngc.collect()\nif DEVICE == \"cuda\":\n    torch.cuda.empty_cache()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T01:13:05.824545Z","iopub.execute_input":"2025-08-28T01:13:05.824735Z","iopub.status.idle":"2025-08-28T01:15:02.803500Z","shell.execute_reply.started":"2025-08-28T01:13:05.824719Z","shell.execute_reply":"2025-08-28T01:15:02.802657Z"}},"outputs":[{"name":"stderr","text":"2025-08-28 01:13:26.363557: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1756343606.691681      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1756343606.784084      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd05969419bd472fa0361e1317f5ecd5"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"submission = pd.DataFrame({\n    \"row_id\": df_test[\"row_id\"],\n    \"rule_violation\": np.round(np.array(probs, dtype=float), 2)\n})\n\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T01:15:02.804372Z","iopub.execute_input":"2025-08-28T01:15:02.804641Z","iopub.status.idle":"2025-08-28T01:15:02.830073Z","shell.execute_reply.started":"2025-08-28T01:15:02.804618Z","shell.execute_reply":"2025-08-28T01:15:02.829283Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   row_id  rule_violation\n0    2029            0.67\n1    2030            0.64\n2    2031            0.50\n3    2032            0.60\n4    2033            0.50","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>rule_violation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2029</td>\n      <td>0.67</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2030</td>\n      <td>0.64</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2031</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2032</td>\n      <td>0.60</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2033</td>\n      <td>0.50</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4}]}