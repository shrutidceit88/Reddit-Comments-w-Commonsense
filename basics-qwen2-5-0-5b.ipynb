{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e208ca1d",
   "metadata": {
    "papermill": {
     "duration": 0.004568,
     "end_time": "2025-09-09T19:35:27.293041",
     "exception": false,
     "start_time": "2025-09-09T19:35:27.288473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook is created with the purpose of understanding the Jigsaw Puzzle using qwen2.5|0.5B. \n",
    "\n",
    "I am also using LoRA optimization technique with the purspose of understanding and ofcourse to make the model consume less computation resources.\n",
    "\n",
    "I intend to understand the basics myself and share my learnings with fellow Kagglers. \n",
    "\n",
    "Please feel free to provide feedback, contribute to the understanding and correct me if need be(I hope Not:-))\n",
    "\n",
    "If you really like the work - Please Upvote:-)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20985aea",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-09T19:35:27.302941Z",
     "iopub.status.busy": "2025-09-09T19:35:27.302139Z",
     "iopub.status.idle": "2025-09-09T19:35:29.265271Z",
     "shell.execute_reply": "2025-09-09T19:35:29.264480Z"
    },
    "papermill": {
     "duration": 1.969628,
     "end_time": "2025-09-09T19:35:29.266715",
     "exception": false,
     "start_time": "2025-09-09T19:35:27.297087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/qwen2.5/transformers/0.5b/1/config.json\n",
      "/kaggle/input/qwen2.5/transformers/0.5b/1/merges.txt\n",
      "/kaggle/input/qwen2.5/transformers/0.5b/1/LICENSE\n",
      "/kaggle/input/qwen2.5/transformers/0.5b/1/README.md\n",
      "/kaggle/input/qwen2.5/transformers/0.5b/1/tokenizer.json\n",
      "/kaggle/input/qwen2.5/transformers/0.5b/1/vocab.json\n",
      "/kaggle/input/qwen2.5/transformers/0.5b/1/tokenizer_config.json\n",
      "/kaggle/input/qwen2.5/transformers/0.5b/1/model.safetensors\n",
      "/kaggle/input/qwen2.5/transformers/0.5b/1/.gitattributes\n",
      "/kaggle/input/qwen2.5/transformers/0.5b/1/generation_config.json\n",
      "/kaggle/input/jigsaw-agile-community-rules/sample_submission.csv\n",
      "/kaggle/input/jigsaw-agile-community-rules/train.csv\n",
      "/kaggle/input/jigsaw-agile-community-rules/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c8ddc7",
   "metadata": {
    "papermill": {
     "duration": 0.003253,
     "end_time": "2025-09-09T19:35:29.273775",
     "exception": false,
     "start_time": "2025-09-09T19:35:29.270522",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Setting Environment Variables\n",
    "\n",
    "<ul>\n",
    "    <li>TOKENIZERS_PARALLELISM controls whether the Hugging Face tokenizers library uses its own internal multi-threading to speed up tokenization.</li>\n",
    "    <li>Reason to disable it is to prevent a conflict with PyTorch's multi-processing data loading, which can lead to deadlocks or severely degraded performance - \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27489553",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:35:29.281879Z",
     "iopub.status.busy": "2025-09-09T19:35:29.281544Z",
     "iopub.status.idle": "2025-09-09T19:36:56.712730Z",
     "shell.execute_reply": "2025-09-09T19:36:56.711707Z"
    },
    "papermill": {
     "duration": 87.437075,
     "end_time": "2025-09-09T19:36:56.714386",
     "exception": false,
     "start_time": "2025-09-09T19:35:29.277311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\r\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\r\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\r\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f82a7f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:36:56.762241Z",
     "iopub.status.busy": "2025-09-09T19:36:56.761895Z",
     "iopub.status.idle": "2025-09-09T19:37:39.758294Z",
     "shell.execute_reply": "2025-09-09T19:37:39.757598Z"
    },
    "papermill": {
     "duration": 43.022132,
     "end_time": "2025-09-09T19:37:39.759805",
     "exception": false,
     "start_time": "2025-09-09T19:36:56.737673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-09 19:37:12.390368: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757446632.739821      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1757446632.846184      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os, gc, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "377114a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:37:39.804067Z",
     "iopub.status.busy": "2025-09-09T19:37:39.803331Z",
     "iopub.status.idle": "2025-09-09T19:37:39.807110Z",
     "shell.execute_reply": "2025-09-09T19:37:39.806379Z"
    },
    "papermill": {
     "duration": 0.026708,
     "end_time": "2025-09-09T19:37:39.808336",
     "exception": false,
     "start_time": "2025-09-09T19:37:39.781628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = \"/kaggle/input/jigsaw-agile-community-rules/train.csv\"\n",
    "model_id  = \"/kaggle/input/qwen2.5/transformers/0.5b/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e8119c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:37:39.850971Z",
     "iopub.status.busy": "2025-09-09T19:37:39.850756Z",
     "iopub.status.idle": "2025-09-09T19:37:39.854186Z",
     "shell.execute_reply": "2025-09-09T19:37:39.853523Z"
    },
    "papermill": {
     "duration": 0.026065,
     "end_time": "2025-09-09T19:37:39.855261",
     "exception": false,
     "start_time": "2025-09-09T19:37:39.829196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "OUT_ROOT  = \"/kaggle/working/qwen25_ce_headonly\"\n",
    "os.makedirs(OUT_ROOT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb18da10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:37:39.898750Z",
     "iopub.status.busy": "2025-09-09T19:37:39.898522Z",
     "iopub.status.idle": "2025-09-09T19:37:39.902118Z",
     "shell.execute_reply": "2025-09-09T19:37:39.901543Z"
    },
    "papermill": {
     "duration": 0.026729,
     "end_time": "2025-09-09T19:37:39.903164",
     "exception": false,
     "start_time": "2025-09-09T19:37:39.876435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED=42; \n",
    "N_FOLDS=5\n",
    "MAX_LEN=512\n",
    "EPOCHS=4\n",
    "TRAIN_BATCH=4\n",
    "GRAD_ACC=4\n",
    "LR=2e-4\n",
    "WARMUP=0.05\n",
    "LABEL_SMOOTH = 0.0  # set 0.05 if you want mild smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10ef7111",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:37:39.946450Z",
     "iopub.status.busy": "2025-09-09T19:37:39.946211Z",
     "iopub.status.idle": "2025-09-09T19:37:39.958582Z",
     "shell.execute_reply": "2025-09-09T19:37:39.957864Z"
    },
    "papermill": {
     "duration": 0.035567,
     "end_time": "2025-09-09T19:37:39.959745",
     "exception": false,
     "start_time": "2025-09-09T19:37:39.924178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(SEED)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb7c491d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:37:40.073405Z",
     "iopub.status.busy": "2025-09-09T19:37:40.072849Z",
     "iopub.status.idle": "2025-09-09T19:37:40.077291Z",
     "shell.execute_reply": "2025-09-09T19:37:40.076484Z"
    },
    "papermill": {
     "duration": 0.030942,
     "end_time": "2025-09-09T19:37:40.078548",
     "exception": false,
     "start_time": "2025-09-09T19:37:40.047606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _trim(x):\n",
    "    x = \"\" if pd.isna(x) else str(x).strip()\n",
    "    return x[:300] if len(x) > 0 else \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d082722f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:37:40.125780Z",
     "iopub.status.busy": "2025-09-09T19:37:40.125037Z",
     "iopub.status.idle": "2025-09-09T19:37:40.129824Z",
     "shell.execute_reply": "2025-09-09T19:37:40.129246Z"
    },
    "papermill": {
     "duration": 0.029511,
     "end_time": "2025-09-09T19:37:40.130886",
     "exception": false,
     "start_time": "2025-09-09T19:37:40.101375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_text_a(row):\n",
    "    sub  = str(row[\"subreddit\"])\n",
    "    rule = str(row[\"rule\"])\n",
    "    pos1 = _trim(row.get(\"positive_example_1\",\"\"))\n",
    "    neg1 = _trim(row.get(\"negative_example_1\",\"\"))\n",
    "    parts = [f\"r/{sub}\", f\"Rule: {rule}\"]\n",
    "    if pos1: parts.append(f\"Yes: {pos1}\")\n",
    "    if neg1: parts.append(f\"No: {neg1}\")\n",
    "    return \" | \".join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d62f590",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:37:40.178174Z",
     "iopub.status.busy": "2025-09-09T19:37:40.177545Z",
     "iopub.status.idle": "2025-09-09T19:37:40.181789Z",
     "shell.execute_reply": "2025-09-09T19:37:40.181028Z"
    },
    "papermill": {
     "duration": 0.029522,
     "end_time": "2025-09-09T19:37:40.182955",
     "exception": false,
     "start_time": "2025-09-09T19:37:40.153433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_df(df):\n",
    "    df = df.copy()\n",
    "    df[\"text_a\"] = df.apply(build_text_a, axis=1)\n",
    "    df[\"text_b\"] = df[\"body\"].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8146e65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:37:40.229161Z",
     "iopub.status.busy": "2025-09-09T19:37:40.228619Z",
     "iopub.status.idle": "2025-09-09T19:37:40.339967Z",
     "shell.execute_reply": "2025-09-09T19:37:40.339158Z"
    },
    "papermill": {
     "duration": 0.136092,
     "end_time": "2025-09-09T19:37:40.341539",
     "exception": false,
     "start_time": "2025-09-09T19:37:40.205447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_data)\n",
    "df = prepare_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3c1dc44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:37:40.387230Z",
     "iopub.status.busy": "2025-09-09T19:37:40.386521Z",
     "iopub.status.idle": "2025-09-09T19:37:40.390634Z",
     "shell.execute_reply": "2025-09-09T19:37:40.389898Z"
    },
    "papermill": {
     "duration": 0.028225,
     "end_time": "2025-09-09T19:37:40.391817",
     "exception": false,
     "start_time": "2025-09-09T19:37:40.363592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target  = df[\"rule_violation\"].astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e717f6a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:37:40.436581Z",
     "iopub.status.busy": "2025-09-09T19:37:40.436370Z",
     "iopub.status.idle": "2025-09-09T19:37:40.927419Z",
     "shell.execute_reply": "2025-09-09T19:37:40.926799Z"
    },
    "papermill": {
     "duration": 0.51484,
     "end_time": "2025-09-09T19:37:40.928718",
     "exception": false,
     "start_time": "2025-09-09T19:37:40.413878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --------------- Tokenizer ---------------\n",
    "tok = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "if tok.pad_token is None:\n",
    "    if tok.eos_token is None:\n",
    "        tok.add_special_tokens({\"eos_token\":\"</s>\"})\n",
    "    tok.pad_token = tok.eos_token\n",
    "    \n",
    "tok.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6ec1f49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:37:40.973920Z",
     "iopub.status.busy": "2025-09-09T19:37:40.973698Z",
     "iopub.status.idle": "2025-09-09T19:37:40.977119Z",
     "shell.execute_reply": "2025-09-09T19:37:40.976552Z"
    },
    "papermill": {
     "duration": 0.02692,
     "end_time": "2025-09-09T19:37:40.978181",
     "exception": false,
     "start_time": "2025-09-09T19:37:40.951261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "collator = DataCollatorWithPadding(tokenizer=tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "396d1fb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:37:41.021716Z",
     "iopub.status.busy": "2025-09-09T19:37:41.021510Z",
     "iopub.status.idle": "2025-09-09T19:37:41.026707Z",
     "shell.execute_reply": "2025-09-09T19:37:41.026028Z"
    },
    "papermill": {
     "duration": 0.028108,
     "end_time": "2025-09-09T19:37:41.027823",
     "exception": false,
     "start_time": "2025-09-09T19:37:40.999715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --------------- Dataset ---------------\n",
    "class PairDataset(Dataset):\n",
    "    def __init__(self, df, labels=None, max_len=256):\n",
    "        self.a = df[\"text_a\"].tolist()\n",
    "        self.b = df[\"text_b\"].tolist()\n",
    "        self.labels = labels\n",
    "        self.max_len = max_len\n",
    "    def __len__(self): return len(self.a)\n",
    "    def __getitem__(self, i):\n",
    "        item = tok(self.a[i], self.b[i], truncation=True, max_length=self.max_len)\n",
    "        if self.labels is not None:\n",
    "            # labels must be Long for CE\n",
    "            item[\"labels\"] = torch.tensor(int(self.labels[i]), dtype=torch.long)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8f67260",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:37:41.073189Z",
     "iopub.status.busy": "2025-09-09T19:37:41.072935Z",
     "iopub.status.idle": "2025-09-09T19:37:41.077815Z",
     "shell.execute_reply": "2025-09-09T19:37:41.077352Z"
    },
    "papermill": {
     "duration": 0.029025,
     "end_time": "2025-09-09T19:37:41.078781",
     "exception": false,
     "start_time": "2025-09-09T19:37:41.049756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --------------- Model (head-only) ---------------\n",
    "def build_headonly_model():\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_id,\n",
    "        num_labels=2,\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=torch.float32,  # keep everything fp32 to avoid dtype mismatches\n",
    "    )\n",
    "    model.config.use_cache = False\n",
    "    model.config.pad_token_id = tok.pad_token_id\n",
    "    model.config.problem_type = \"single_label_classification\"\n",
    "\n",
    "    # keep embeddings in sync if special tokens were added\n",
    "    if model.get_input_embeddings().num_embeddings != len(tok):\n",
    "        model.resize_token_embeddings(len(tok))\n",
    "\n",
    "    # fresh classifier head\n",
    "    hidden = model.config.hidden_size\n",
    "    model.score = nn.Linear(hidden, 2)\n",
    "    nn.init.xavier_uniform_(model.score.weight)\n",
    "    nn.init.zeros_(model.score.bias)\n",
    "\n",
    "    # freeze everything except the classifier head\n",
    "    for n, p in model.named_parameters():\n",
    "        p.requires_grad = (\"score\" in n)\n",
    "\n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f96bf742",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:37:41.121941Z",
     "iopub.status.busy": "2025-09-09T19:37:41.121734Z",
     "iopub.status.idle": "2025-09-09T19:37:41.125317Z",
     "shell.execute_reply": "2025-09-09T19:37:41.124801Z"
    },
    "papermill": {
     "duration": 0.026377,
     "end_time": "2025-09-09T19:37:41.126372",
     "exception": false,
     "start_time": "2025-09-09T19:37:41.099995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --------------- Weighted CE & safe FP32 loss ---------------\n",
    "pos_frac = float(target.mean())\n",
    "neg_frac = 1.0 - pos_frac\n",
    "\n",
    "# class_weights shape [2] on same device as model; weight(neg)=1, weight(pos)=neg/pos\n",
    "cw = torch.tensor([1.0, (neg_frac / max(pos_frac, 1e-6))], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8d45a8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:37:41.170251Z",
     "iopub.status.busy": "2025-09-09T19:37:41.169801Z",
     "iopub.status.idle": "2025-09-09T19:37:41.174642Z",
     "shell.execute_reply": "2025-09-09T19:37:41.174012Z"
    },
    "papermill": {
     "duration": 0.028261,
     "end_time": "2025-09-09T19:37:41.175763",
     "exception": false,
     "start_time": "2025-09-09T19:37:41.147502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FP32Trainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None, **kwargs):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        inputs = {k: v for k, v in inputs.items() if k != \"labels\"}\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits.float()  # always compute loss in FP32\n",
    "\n",
    "        # move class weights to correct device only here (model may be on GPU/CPU)\n",
    "        loss_fct = nn.CrossEntropyLoss(\n",
    "            weight=cw.to(logits.device),\n",
    "            label_smoothing=LABEL_SMOOTH\n",
    "        )\n",
    "        loss = loss_fct(logits.view(-1, 2), labels.view(-1))\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bf648db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:37:41.219902Z",
     "iopub.status.busy": "2025-09-09T19:37:41.219649Z",
     "iopub.status.idle": "2025-09-09T19:37:41.223430Z",
     "shell.execute_reply": "2025-09-09T19:37:41.222768Z"
    },
    "papermill": {
     "duration": 0.026865,
     "end_time": "2025-09-09T19:37:41.224589",
     "exception": false,
     "start_time": "2025-09-09T19:37:41.197724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --------------- CV Train ---------------\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "oof = np.zeros(len(df), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9bf36b67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T19:37:41.269209Z",
     "iopub.status.busy": "2025-09-09T19:37:41.268959Z",
     "iopub.status.idle": "2025-09-09T20:22:11.838555Z",
     "shell.execute_reply": "2025-09-09T20:22:11.837443Z"
    },
    "papermill": {
     "duration": 2670.594487,
     "end_time": "2025-09-09T20:22:11.840822",
     "exception": false,
     "start_time": "2025-09-09T19:37:41.246335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1/5 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/qwen2.5/transformers/0.5b/1 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='204' max='204' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [204/204 08:08, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.270700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.943000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.591800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.537100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved fold 1 to /kaggle/working/qwen25_ce_headonly/fold1\n",
      "Fold 1 AUC: 0.6948\n",
      "\n",
      "===== Fold 2/5 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/qwen2.5/transformers/0.5b/1 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='204' max='204' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [204/204 08:15, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.181900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.137400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.839500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.723800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved fold 2 to /kaggle/working/qwen25_ce_headonly/fold2\n",
      "Fold 2 AUC: 0.6341\n",
      "\n",
      "===== Fold 3/5 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/qwen2.5/transformers/0.5b/1 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='204' max='204' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [204/204 08:13, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.362700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.133200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.826000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.704300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved fold 3 to /kaggle/working/qwen25_ce_headonly/fold3\n",
      "Fold 3 AUC: 0.6708\n",
      "\n",
      "===== Fold 4/5 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/qwen2.5/transformers/0.5b/1 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='204' max='204' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [204/204 08:15, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.009400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.815900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.685800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved fold 4 to /kaggle/working/qwen25_ce_headonly/fold4\n",
      "Fold 4 AUC: 0.6096\n",
      "\n",
      "===== Fold 5/5 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/qwen2.5/transformers/0.5b/1 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='204' max='204' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [204/204 08:13, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.349400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.138800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.822200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.676100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved fold 5 to /kaggle/working/qwen25_ce_headonly/fold5\n",
      "Fold 5 AUC: 0.6464\n"
     ]
    }
   ],
   "source": [
    "for fold, (trn_idx, val_idx) in enumerate(skf.split(df, target), 1):\n",
    "    print(f\"\\n===== Fold {fold}/{N_FOLDS} =====\")\n",
    "    dtr = PairDataset(df.iloc[trn_idx], target[trn_idx], MAX_LEN)\n",
    "    dvl = PairDataset(df.iloc[val_idx], target[val_idx], MAX_LEN)\n",
    "\n",
    "    model = build_headonly_model()\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=f\"{OUT_ROOT}/fold{fold}\",\n",
    "        num_train_epochs=EPOCHS,\n",
    "        per_device_train_batch_size=TRAIN_BATCH,\n",
    "        gradient_accumulation_steps=GRAD_ACC,\n",
    "        learning_rate=LR,\n",
    "        warmup_ratio=WARMUP,\n",
    "        weight_decay=0.01,\n",
    "        logging_steps=50,\n",
    "        save_strategy=\"no\",          # keep training simple (no checkpointing)\n",
    "        report_to=\"none\",\n",
    "        remove_unused_columns=False,\n",
    "        fp16=False, bf16=False,      # keep pure FP32 to avoid dtype issues\n",
    "        dataloader_pin_memory=False,\n",
    "        seed=SEED,\n",
    "    )\n",
    "\n",
    "    trainer = FP32Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=dtr,\n",
    "        tokenizer=tok,\n",
    "        data_collator=collator,\n",
    "    )\n",
    "\n",
    "    # quick sanity forward to ensure tensors/devices OK (no grads)\n",
    "    tmp_loader = DataLoader(dtr, batch_size=2, shuffle=False, collate_fn=collator)\n",
    "    batch = next(iter(tmp_loader))\n",
    "    for k in batch: batch[k] = batch[k].to(device)\n",
    "    with torch.no_grad():\n",
    "        _ = model(**{k:v for k,v in batch.items() if k!=\"labels\"})\n",
    "    del tmp_loader, batch; gc.collect()\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # Save fold weights & tokenizer\n",
    "    save_dir = f\"{OUT_ROOT}/fold{fold}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    trainer.model.save_pretrained(save_dir)\n",
    "    tok.save_pretrained(save_dir)\n",
    "    print(f\"Saved fold {fold} to {save_dir}\")\n",
    "\n",
    "    # ---------- OOF AUC ----------\n",
    "    model.eval()\n",
    "    dl = DataLoader(dvl, batch_size=128, shuffle=False, collate_fn=collator)\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dl:\n",
    "            for k in batch: batch[k] = batch[k].to(device)\n",
    "            logits = model(**{k:v for k,v in batch.items() if k!=\"labels\"}).logits.float()\n",
    "            logits = torch.nan_to_num(logits, nan=0.0, posinf=1e4, neginf=-1e4)\n",
    "            prob = torch.softmax(logits, dim=1)[:, 1]\n",
    "            prob = torch.nan_to_num(prob, nan=0.5)\n",
    "            preds.append(prob.detach().cpu().numpy())\n",
    "\n",
    "    prob1 = np.concatenate(preds)\n",
    "    prob1 = np.clip(prob1, 0.0, 1.0)\n",
    "    if np.isnan(prob1).any():\n",
    "        prob1 = np.nan_to_num(prob1, nan=0.5)\n",
    "\n",
    "    oof[val_idx] = prob1\n",
    "    print(f\"Fold {fold} AUC: {roc_auc_score(target[val_idx], prob1):.4f}\")\n",
    "\n",
    "    del trainer, model, dtr, dvl, dl, preds, prob1\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75dcec03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T20:22:11.975931Z",
     "iopub.status.busy": "2025-09-09T20:22:11.975658Z",
     "iopub.status.idle": "2025-09-09T20:22:12.000565Z",
     "shell.execute_reply": "2025-09-09T20:22:11.999762Z"
    },
    "papermill": {
     "duration": 0.087815,
     "end_time": "2025-09-09T20:22:12.001839",
     "exception": false,
     "start_time": "2025-09-09T20:22:11.914024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OOF AUC: 0.6510\n",
      "Saved folds under: /kaggle/working/qwen25_ce_headonly\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nOOF AUC: {roc_auc_score(target, oof):.4f}\")\n",
    "pd.DataFrame({\"oof\": oof, \"y\": target}).to_csv(f\"{OUT_ROOT}/oof.csv\", index=False)\n",
    "print(\"Saved folds under:\", OUT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95cb5a2",
   "metadata": {
    "papermill": {
     "duration": 0.03227,
     "end_time": "2025-09-09T20:22:12.069555",
     "exception": false,
     "start_time": "2025-09-09T20:22:12.037285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13121456,
     "sourceId": 94635,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 164048,
     "modelInstanceId": 141432,
     "sourceId": 166218,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2814.32218,
   "end_time": "2025-09-09T20:22:15.545548",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-09T19:35:21.223368",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
